% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/paa_poisson.R
\name{paa_poisson}
\alias{paa_poisson}
\alias{paa_poisson_free}
\alias{paa_normal_free}
\alias{paa_nb_free}
\alias{poisson_mixture}
\title{Create probabilistic archetypal analysis model in greta (tensorflow backend)}
\usage{
paa_poisson(data, n_arc = 7, weight_alpha_prior = 0.8,
  c_alpha_prior = 0.001, covar = NULL, precision = c("double",
  "single"))

paa_poisson_free(data, n_arc = 7, weight_alpha_prior = 0.8,
  scale_data_sd = 0.2, covar = NULL, precision = c("double",
  "single"), ...)

paa_normal_free(data, n_arc = 7, weight_alpha_prior = 0.8,
  scale_data_sd = 0.2, covar = NULL, precision = c("double",
  "single"), ...)

paa_nb_free(data, n_arc = 7, weight_alpha_prior = 0.8,
  scale_data_sd = 0.2, covar = NULL, precision = c("double",
  "single"), ...)

poisson_mixture(data, n_arc = 7, weight_alpha_prior = 0.8,
  scale_data_sd = 0.2, covar = NULL, precision = c("double",
  "single"), ...)
}
\arguments{
\item{data}{matrix of positive count data: data points * dimensions. At the moment, greta does not support sparse matrix.}

\item{n_arc}{number of archetypes}

\item{weight_alpha_prior}{dirichet distrubution on archetype weights (sum to 1 for each data point). Value of 1 means flat distribution (all weights are equally likely to occur), less than 1 means sparse distribution (weights are likely to be close to 0 or close to 1), greater than 1 means the weights are less likely to be close to 0 or 1. To get a better idea on the meaning of this prior try sampling with different alpha values \code{alpha = c(0.8, 0.8); extraDistr::rdirichlet(1e5, alpha)}, where length(alpha) is the number of archetypes.}

\item{c_alpha_prior}{archetype construction weights c. Analogous to \code{weight_alpha_prior}, but set very close to 0 to enforce sparsity.}

\item{covar}{matrix of covariates affecting the expression (mu) in addition to archetypes: data points * n_covariates}

\item{precision}{argument for \link[greta]{model}. Use "single" for large datasets to reduce memory footprint}

\item{scale_data_sd}{by what factor to scale sd(data)}

\item{...}{unused - temporary hack to make paa models easier to exchange}

\item{scale_data_sd}{by what factor to scale sd(data)}

\item{...}{unused - temporary hack to make paa models easier to exchange}
}
\value{
\code{poisson_regression()}: R environment containing the model and parameters as greta arrays
}
\description{
\code{paa_poisson()} creates Archetypal Analysis greta model with Poisson likelihood function:

data = Poisson(mu)

mu = weights * archetypes

archetypes = c * data

Covariates can be added (experimental):

mu = exp(log(weights * archetypes) + beta * covar)

\code{paa_poisson_free()} creates Archetypal Analysis greta model with Poisson likelihood function:

data = Poisson(mu)

mu = exp(weights * archetypes)

archetypes = Normal(mean = mean(data), sd = sd(data))

\code{paa_normal_free()} creates Archetypal Analysis greta model with Normal likelihood function:

data = Normal(mean = mu, sd)

mu = weights * archetypes_mean

sd = weights * archetypes_sd

archetypes_mean = Normal(mean = mean(data), sd = sd(data))

archetypes_sd = Exponential(rate = 1 / sd(data))

\code{paa_nb_free()} creates Archetypal Analysis greta model with Negative binomial likelihood function:

data = NegativeBinomial(prob = prob, size = size)

prob = size / (size + mu)

mu = weights * archetypes_mean

size = weights * archetypes_size

archetypes_mean = Normal(mean = mean(data), sd = sd(data), truncation = c(0, Inf))

archetypes_size = Exponential(rate = (mean(data) + mean(data)^2) / var(data))

\code{poisson_mixture()} creates Archetypal Analysis greta model with Poisson likelihood function:

data = Poisson(mu)

mu = exp(weights * archetypes)

archetypes = Normal(mean = mean(data), sd = sd(data))
}
\examples{
# create greta / tensorflow model
m = paa_poisson(data,              # data: data points * dimensions
                n_arc = 7,              # number of achetypes
                weight_alpha_prior = 0.8,
                c_alpha_prior = 0.001,
                precision = options$precision
)

# visualise computation graph
plot(m$model)

# solve model with optimisation
opt_res = opt(m$model,
                optimiser = adam(learning_rate = 0.3),   # optimisation method used to find prior-adjusted maximum likelihood estimate: adam, l_bfgs_b,
                max_iterations = 500,
                tolerance = 1e-4, adjust = TRUE,
                hessian = FALSE)

# calculate archetypes using c matrix
archetypes = opt_res$par$c \%*\% data
}
